{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake data\n",
    "\n",
    "This is a notebook for generating data for use in the exerises.\n",
    "\n",
    "This uses dataframes, so if it doesn't make sense to you, that's perfectly normal. So far you've only learned about Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URLs to pull from \n",
    "CENSUS_SURNAME_URL = 'https://www2.census.gov/topics/genealogy/2010surnames/Names_2010Census_Top1000.xlsx'\n",
    "HADLEY_FORENAME_URL = 'https://github.com/hadley/data-baby-names/raw/master/baby-names.csv'\n",
    "\n",
    "# Note: you probably don't haven't set up a FRED environment variable so this will fail.\n",
    "UNEMPLOYMENT_URL = 'https://api.stlouisfed.org/fred/series/observations?series_id=UNRATE&api_key={}&file_type=json'.format(os.environ['FRED_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = pd.Series([\n",
    "    50,\n",
    "    100,\n",
    "    150,\n",
    "    100,\n",
    "    50,\n",
    "],\n",
    "name='data')\n",
    "\n",
    "simple.to_csv('./data/simple.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas can read CSVs directly from the internet\n",
    "forenames = pd.read_csv(HADLEY_FORENAME_URL)\n",
    "forenames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now an Excel\n",
    "surnames = pd.read_excel(CENSUS_SURNAME_URL, header=1)['SURNAME']\n",
    "\n",
    "# Drop junk on end\n",
    "surnames = surnames.head(1000).str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forenames from after 2000.\n",
    "modern_forenames = forenames.loc[forenames['year'] > 2000, 'name']\n",
    "\n",
    "# Get a sample of 1,000.\n",
    "forename_sample = modern_forenames.sample(1000)\n",
    "\n",
    "# Replace 10% of those with 'Steve'\n",
    "forename_sample.iloc[:int(len(forename_sample) / 10)] = 'Steve'\n",
    "forename_sample.index = pd.RangeIndex(0,1000)# Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "forename_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show\n",
    "surnames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make combos\n",
    "full_names = forename_sample + ' ' + surnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example\n",
    "full_names.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file.\n",
    "full_names.name = 'names'\n",
    "full_names.to_csv('data/subject_names.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Generation\n",
    "\n",
    "Using a normally distributed height of 172 pounds and a standard deviation of 29 pounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "weight = pd.Series(\n",
    "    data=stats.norm.rvs(loc=172, scale=29, size=1000)\n",
    ")\n",
    "\n",
    "# Round it\n",
    "rounded_w = weight.round(2)\n",
    "\n",
    "# Add nans\n",
    "nan_ix = rounded_w.sample(frac=.2).index.values\n",
    "rounded_w.loc[nan_ix] = np.NaN\n",
    "\n",
    "\n",
    "# Write it to disk.\n",
    "rounded_w.name = 'pounds'\n",
    "rounded_w.to_csv('data/weight_in_pounds.csv', header=True, index=False)\n",
    "\n",
    "# Display\n",
    "rounded_w.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height Generation\n",
    "\n",
    "Using a normally distributed height of 5.66 feet (68 inches) and stdev of .33 (4 inches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random data\n",
    "height = pd.Series(\n",
    "    data=stats.norm.rvs(loc=5.66, scale=.33, size=1000)\n",
    ")\n",
    "\n",
    "# Round it\n",
    "rounded_h = height.round(2)\n",
    "\n",
    "# Add nans\n",
    "nan_ix = rounded_h.sample(frac=.2).index.values\n",
    "rounded_h.loc[nan_ix] = np.NaN\n",
    "\n",
    "# Write it to disk.\n",
    "rounded_h.name = 'feet'\n",
    "rounded_h.to_csv('data/height_in_feet.csv', header=True, index=False)\n",
    "\n",
    "# Display\n",
    "rounded_h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spy and Staff Generation\n",
    "\n",
    "Create a list of spies and embassy staff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spies = pd.Series({\n",
    "    'Mata'    : 40,\n",
    "    'Casanova': 41,\n",
    "    'Julius'  : 51,\n",
    "    'Ethel'   : 48,\n",
    "    'Klaus'   : 35,\n",
    "    'Belle'   : 30,\n",
    "    'Valery'  : 28,\n",
    "})\n",
    "\n",
    "embassy_staff = pd.Series({\n",
    "    'Dave'    : 30,\n",
    "    'Julius'  : 51,\n",
    "    'Ethel'   : 48,\n",
    "    'Jenna'   : 25,\n",
    "    'Klaus'   : 35,\n",
    "    'Aloysius': 84,\n",
    "    'Carlos'  : 40,\n",
    "    'Michael' : 28,\n",
    "    'Tito'    : 32,\n",
    "    'Jermaine': 30,\n",
    "    'Janet'   : 28,\n",
    "    'Marlon'  : 25,\n",
    "    'Jackie'  : 22,\n",
    "})\n",
    "\n",
    "# No headers\n",
    "spies.to_csv('data/spies.csv')\n",
    "embassy_staff.to_csv('data/embassy_staff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some datetime csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dates\n",
    "datetimes = pd.Series(pd.date_range(start='2020-01-01', end='2020-01-02', freq='H'), name='dts')\n",
    "datetimes.to_csv('data/datetimes.csv', index=False, header=True)\n",
    "\n",
    "# Generate periods\n",
    "periods = pd.Series(pd.period_range(start='2020-01-01', end='2020-01-02', freq='H'), name='periods')\n",
    "datetimes.to_csv('data/periods.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate morse code CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse_dict = {\n",
    "    '\"': '. _ . . _ .', \"'\": '. _ _ _ _ .', '(': '_ . _ _ .'  , ')': '_ . _ _ . _',\n",
    "    'x': '_ . . _'    , '+': '. _ . _ .'  , ',': '_ _ . . _ _', '-': '_ . . . . _',\n",
    "    '.': '. _ . _ . _', '/': '_ . . _ .'  , '0': '_ _ _ _ _'  , '1': '. _ _ _ _'  ,\n",
    "    '2': '. . _ _ _'  , '3': '. . . _ _'  , '4': '. . . . _'  , '5': '. . . . .'  ,\n",
    "    '6': '_ . . . .'  , '7': '_ _ . . .'  , '8': '_ _ _ . .'  , '9': '_ _ _ _ .'  ,\n",
    "    ':': '_ _ _ . . .', ';': '_ . _ . _ .', '=': '_ . . . _'  , '?': '. . _ _ . .',\n",
    "    '@': '. _ _ . _ .', 'A': '. _'        , 'B': '_ . . .'    , 'C': '_ . _ .'    ,\n",
    "    'D': '_ . .'      , 'E': '.'          , 'F': '. . _ .'    , 'G': '_ _ .'      ,\n",
    "    'H': '. . . .'    , 'I': '. .'        , 'J': '. _ _ _'    , 'K': '_ . _'      ,\n",
    "    'L': '. _ . .'    , 'M': '_ _'        , 'N': '_ .'        , 'O': '_ _ _'      ,\n",
    "    'P': '. _ _ .'    , 'Q': '_ _ . _'    , 'R': '. _ .'      , 'S': '. . .'      ,\n",
    "    'T': '_'          , 'U': '. . _'      , 'V': '. . . _'    , 'W': '. _ _'      ,\n",
    "    'X': '_ . . _'    , 'Y': '_ . _ _'    , 'Z': '_ _ . .'    , '_': '. . _ _ . _',\n",
    "}\n",
    "\n",
    "morse_series            = pd.Series(morse_dict)\n",
    "morse_series.name       = 'morse_representation'\n",
    "morse_series.index.name = 'character'\n",
    "morse_series.sort_index().to_csv('./data/morse.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Life of Brian characters\n",
    "lob_characters = pd.Series(\n",
    "    name='characters',\n",
    "    data=[\n",
    "        'Brian',\n",
    "        'NA',\n",
    "        'Centurion of the Yard',\n",
    "        'Gaoler',\n",
    "        'NA',\n",
    "        'Harry the Haggler',\n",
    "        'Ex-Leper',\n",
    "        'Gregory',\n",
    "        'Judith Escariot',\n",
    "        'Simon the Holy Man',\n",
    "        'Pontius Pilate',\n",
    "        'Matthias',\n",
    "        'Gregory',\n",
    "        'NA',\n",
    "        'Gaoler',\n",
    "        'Brian',\n",
    "        'Simon the Holy Man',\n",
    "        'NA',\n",
    "        'NA',\n",
    "        'Gregory',\n",
    "        'Gregory',\n",
    "        'Gregory',\n",
    "        'Ex-Leper',\n",
    "        'Gregory',\n",
    "        'Simon the Holy Man',\n",
    "        'Matthias',\n",
    "        'NA',\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write\n",
    "lob_characters.to_csv('./data/lob_characters.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unemployment Data from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data from FRED using API key (won't work for you without setup)\n",
    "r = requests.get(UNEMPLOYMENT_URL)\n",
    "data = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "observations = pd.read_json(data)['observations']\n",
    "dates = observations.map(lambda x: x['date'])\n",
    "values = observations.map(lambda x: x['value'])\n",
    "ix = pd.PeriodIndex(dates.values, freq='M')\n",
    "\n",
    "# Create series\n",
    "unemployment = pd.Series(\n",
    "    index=ix,\n",
    "    data=percent.values,\n",
    ")\n",
    "\n",
    "# chopped\n",
    "chopped = unemployment.loc['2000':]\n",
    "chopped.index.name = 'month'\n",
    "chopped.name = 'unemployment_rate'\n",
    "chopped.to_csv('./data/unemployment.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dummy groupby data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LENGTH = 1000\n",
    "\n",
    "# Distribution dict\n",
    "salary_data = {\n",
    "    'Tinker' : {'prob': .15, 'mean': 35000, 'std': .05},\n",
    "    'Tailor' : {'prob': .10, 'mean': 45000, 'std': .20},\n",
    "    'Soldier': {'prob': .70, 'mean': 40000, 'std': .00},\n",
    "    'Spy'    : {'prob': .05, 'mean': 80000, 'std': .50},\n",
    "}\n",
    "\n",
    "# Create randomly generator professions\n",
    "professions = pd.Series(\n",
    "    np.random.choice(\n",
    "        list(salary_data.keys()),\n",
    "        p=[salary_data[name]['prob'] for name in salary_data.keys()],\n",
    "        size=1000, \n",
    "    )\n",
    ")\n",
    "\n",
    "# Output proefssions\n",
    "professions.name = 'profession'\n",
    "professions.to_csv('./data/professions.csv', index=False, header=True)\n",
    "\n",
    "\n",
    "# Tranform function\n",
    "def gen_probs(df, data):\n",
    "    #return df.iloc[0]\n",
    "    key = df.iloc[0]\n",
    "    mean = data[key]['mean']\n",
    "    std = data[key]['std'] * mean\n",
    "    norm_dist = stats.norm.rvs(loc=mean, scale=std, size=len(df))\n",
    "    return norm_dist\n",
    "\n",
    "\n",
    "# Generate salaries.\n",
    "salaries = professions.groupby(professions).transform(gen_probs, salary_data)\n",
    "salaries = salaries.round(2)\n",
    "salaries.name = 'salary'\n",
    "salaries.to_csv('./data/salaries.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make mixed type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_bag = pd.Series(['2018-01-01', 4, 2.0, '2019-01-01', '12/31/2015', 2.8, 'hola!', 2.9 ,'NA'])\n",
    "mixed_bag.name = 'hot_mess'\n",
    "mixed_bag.to_csv('./data/mixed_bag.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
