{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://github.com/theonaunheim\">\n",
    "    <img style=\"border-radius: 100%; float: right;\" src=\"static/strawberry_thief_square.png\" width=10% alt=\"Theo Naunheim's Github\">\n",
    "</a>\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<h1 align='center'>Exercises</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: table; width: 100%\">\n",
    "    <div style=\"display: table-row; width: 100%;\">\n",
    "        <div style=\"display: table-cell; width: 50%; vertical-align: middle;\">\n",
    "          \n",
    "<h1 align=\"center\"> $W=-\\Delta PE$ </h1>\n",
    "          \n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 10%\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 40%; vertical-align: top;\">\n",
    "            <blockquote>\n",
    "                <p style=\"font-style: italic;\">\"I fear not the man who has practiced 10,000 kicks once, but I fear the man who has practiced one kick 10,000 times.</p>\n",
    "                <br>\n",
    "                <p>- Bruce Lee</p>\n",
    "            </blockquote>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "1) Import:\n",
    "* pandas\n",
    "* a random forest regressor from sklearn.ensemble.\n",
    "\n",
    "3) Load the data/mpg.csv dataset and drop NaN values. Make:\n",
    "* horsepower, weight, and cylinders as X; and,\n",
    "* mpg as y. \n",
    "\n",
    "4) fit() your model.\n",
    "\n",
    "5) predict() the mpg of a car with:\n",
    "* horsepower of 300;\n",
    "* weight of 4000; and,\n",
    "* 8 cylinders\n",
    "\n",
    "6) Run your code again. Did your result change slightly?\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Remember that predict wants a list of lists like [[400, 500, 4]]\n",
    "\n",
    "**Hint**: In real life, remember to scale and split your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "1) Import:\n",
    "* the Support Vector Classifier from sklearn.svm\n",
    "\n",
    "2) Load the data/iris.csv dataset. And set:\n",
    "* 'sepal_length', 'sepal_width', 'petal_width', 'petal_length' as X; and,\n",
    "* 'species as y.\n",
    "\n",
    "3) Create your Support Vector Classifier with the kernel='linear' argument.\n",
    "\n",
    "4) Fit your SVC.\n",
    "\n",
    "5) Try predict() on the following data:\n",
    "* [5.0, 3.5, 1.5, 0.2]\n",
    "* [6.5, 3.0, 5.0, 2.0]\n",
    "    \n",
    "6) Print your predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Support Vector Classifier is abbreviated as SVC.\n",
    "\n",
    "**Hint**: Remember that predict wants a list of lists like [[400, 500, 4]]\n",
    "\n",
    "**Hint**: In real life, remember to scale and split your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "1) Import:\n",
    "* StandardScaler from sklearn.preprocessing\n",
    "\n",
    "2) Load the data/housing.csv dataset.\n",
    "\n",
    "3) Create the scaler.\n",
    "\n",
    "4) fit() the entire dataset.\n",
    "\n",
    "5) transform() the entire dataset and save the results to 'scaled_data'.\n",
    "\n",
    "6) Bonus points: can you inverse_transform() the scaled_data?\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Inverse transform is also attached to the scaler instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "1) Import:\n",
    "* train_test_split from sklearn.model_selection\n",
    "\n",
    "2) Load your data from data/housing.csv. Split:\n",
    "* y: 'Value'\n",
    "* X: everything else\n",
    "\n",
    "3) Use train_test_split with test_size=.30\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Use DataFrame.drop('column', axis=1) to drop a column and return df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "1) Import:\n",
    "* GradientBoostingRegressor from sklearn.ensemble;\n",
    "* Pipeline from sklearn.pipeline; and,\n",
    "* Imputer from sklearn.preprocessing.\n",
    "\n",
    "2) Create a pipeline composed of:\n",
    "* An imputer with a missing_values=np.NaN argument;\n",
    "* A standard scaler; and,\n",
    "* A gradient boosting regressor.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Don't forget to name your pipeline steps.\n",
    "\n",
    "**Hint**: Pipelines are composed of a list of tuples:\n",
    "    \n",
    "    Pipeline([\n",
    "        ('step_1', Item()),\n",
    "        ('step_2', Item())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 6\n",
    "\n",
    "1) Import:\n",
    "* import mean_squared_error from sklearn.metrics\n",
    "\n",
    "2) Take 'pipe' from Exercise 5 and fit():\n",
    "* 'X_train' from Exercise 4\n",
    "* 'y_train' from Exercise 4.\n",
    "\n",
    "3) predict() using 'X_test' from Exercise 4, and assign to 'y_predicted'\n",
    "\n",
    "4) Get your mean_squared_error from 'y_test' from Excercise 4 and 'y_predicted'.\n",
    "\n",
    "5) Bonus: reconsitute X_test with y_test, y_predicted, and the diff between them.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: nothing new aside from the bonus. Just make sure everything goes in the right spot.\n",
    "\n",
    "**Bonus Hint**: bonus is easiest by creating a y_out dataframe, then concatenating to X_test.\n",
    "\n",
    "**Bonus Hint**: remember to concatenate along the 1 axis (colums) as opposed to the 0 axis (rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 7\n",
    "\n",
    "1) Import:\n",
    "* import cross_val_score from the sklearn.model_selection module.\n",
    "\n",
    "2) Take 'pipe' from Exercise 5 and run a 5-fold cross-validation score with:\n",
    "* X from Exercise 4;\n",
    "* y from Exervise 4; and,\n",
    "* an error type string from the 'scoring' column this [table](http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n",
    "3) Print the average error score.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: you are doing a cross-validation so no train/test split is required (i.e. don't use X_train, use X).\n",
    "\n",
    "**Hint**: you are fitting a regressor, so your error scoring will need to be under \"Regression\" in the table. Classifier items will error out.\n",
    "\n",
    "**Hint**: You can find what parameters need to feed model_selection on the API [cross_val_score page](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). It's in the grey box.\n",
    "\n",
    "**Hint**: the 'cv' keyword argument corresponds with the number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 8\n",
    "\n",
    "1) Import:\n",
    "* import GridSearchCV from the sklearn.model_selection module.\n",
    "\n",
    "2) Create a parameter grid for your pipeline with so that we test:\n",
    "* 'ls' and 'huber' as your loss function for your regressor; and,\n",
    "* 'n_estimators' is set for 25 instead of 100 to save time.\n",
    "\n",
    "3) Create a grid search for your pipe using your parameter grid. Assign the result to 'best_model'.\n",
    "\n",
    "4) Fit your model on:\n",
    "* X_train from Exercise 4; and,\n",
    "* y_train from Exercise 4.\n",
    "\n",
    "5) Predict X_test with your model.\n",
    "\n",
    "6) Bonus: print out the models best parameters.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Parameter grid template [here](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py). You can also look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). It will look something like this (note the double underscore between the name and keyword argument:\n",
    "\n",
    "    grid = {\n",
    "        'regressor__loss'        : ['ls', 'huber'],\n",
    "        'regressor__n_estimators': [25]\n",
    "    }\n",
    "\n",
    "**Hint**: GridSearchCV() will return your optimal model.\n",
    "\n",
    "**Bonus Hint**: the best parameters will be under the .best_params_ attribute of the return value of GridSearchCV()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Excercise 9\n",
    "\n",
    "1) Pick a dataset to work on from the data folder.\n",
    "\n",
    "2) Load the data and look at it. Pick out feature variables and a target variable.\n",
    "\n",
    "3) If your target is a category, pick a classifier algo. Otherwise pick a regressor algo.\n",
    "\n",
    "4) Scale your data, fit your model, and make some predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: When in doubt, Google!\n",
    "\n",
    "**Hint**: When in doubt, look at the sklearn documentation and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 10\n",
    "\n",
    "1) Take your algorithm from Exercise 9, and recreate it with tweaked parameters and make predictions on the data.\n",
    "\n",
    "2) Use a scorer of your choice to compare the results of models to see which is better.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: When in doubt, Google!\n",
    "\n",
    "**Hint**: When in doubt, look at the sklearn documentation and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Next Up: [Solutions](8_solutions.ipynb)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
