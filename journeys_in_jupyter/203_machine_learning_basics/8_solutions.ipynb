{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a href=\"https://github.com/theonaunheim\">\n",
    "    <img style=\"border-radius: 100%; float: right;\" src=\"static/strawberry_thief_square.png\" width=10% alt=\"Theo Naunheim's Github\">\n",
    "</a>\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<h1 align='center'>Solutions</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: table; width: 100%\">\n",
    "    <div style=\"display: table-row; width: 100%;\">\n",
    "        <div style=\"display: table-cell; width: 50%; vertical-align: middle;\">\n",
    "          \n",
    "<h1 align=\"center\"> $W=\\Delta KE$ </h1>\n",
    "          \n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 10%\">\n",
    "        </div>\n",
    "        <div style=\"display: table-cell; width: 40%; vertical-align: top;\">\n",
    "            <blockquote>\n",
    "                <p style=\"font-style: italic;\">\"The best practice for Judo is Judo.</p>\n",
    "                <br>\n",
    "                <p>- Seishiro Okazaki</p>\n",
    "            </blockquote>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 1\n",
    "\n",
    "1) Import:\n",
    "* pandas\n",
    "* a random forest regressor from sklearn.ensemble.\n",
    "\n",
    "3) Load the data/mpg.csv dataset and drop NaN values. Make:\n",
    "* horsepower, weight, and cylinders as X; and,\n",
    "* mpg as y. \n",
    "\n",
    "4) fit() your model.\n",
    "\n",
    "5) predict() the mpg of a car with:\n",
    "* horsepower of 300;\n",
    "* weight of 4000; and,\n",
    "* 8 cylinders\n",
    "\n",
    "6) Run your code again. Did your result change slightly?\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Remember that predict wants a list of lists like [[400, 500, 4]]\n",
    "\n",
    "**Hint**: In real life, remember to scale and split your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction is:\n",
      "[ 14.25]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load data and put into X and y.\n",
    "df = pd.read_csv('data/mpg.csv')\n",
    "df = df.dropna()\n",
    "X  = df[['horsepower', 'weight', 'cylinders']]\n",
    "y  = df['mpg']\n",
    "\n",
    "# Create SVR\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, y)\n",
    "\n",
    "# Predict 300 horsepower, 4000 pound car, 8 cyl car.\n",
    "prediction = rfr.predict([[300, 4000, 8]])\n",
    "print('Our prediction is:')\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 2\n",
    "\n",
    "1) Import:\n",
    "* the Support Vector Classifier from sklearn.svm\n",
    "\n",
    "2) Load the data/iris.csv dataset. And set:\n",
    "* 'sepal_length', 'sepal_width', 'petal_width', 'petal_length' as X; and,\n",
    "* 'species as y.\n",
    "\n",
    "3) Create your Support Vector Classifier with the kernel='linear' argument.\n",
    "\n",
    "4) Fit your SVC.\n",
    "\n",
    "5) Try predict() on the following data:\n",
    "* [5.0, 3.5, 1.5, 0.2]\n",
    "* [6.5, 3.0, 5.0, 2.0]\n",
    "    \n",
    "6) Print your predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Support Vector Classifier is abbreviated as SVC.\n",
    "\n",
    "**Hint**: Remember that predict wants a list of lists like [[400, 500, 4]]\n",
    "\n",
    "**Hint**: In real life, remember to scale and split your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/iris.csv')\n",
    "X = df[[\n",
    "    'sepal_length', \n",
    "    'sepal_width',\n",
    "    'petal_width', \n",
    "    'petal_length', \n",
    "]]\n",
    "y = df['species']\n",
    "\n",
    "# Create yoru classifier with class weight\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Fit your classifier\n",
    "svc.fit(X, y)\n",
    "\n",
    "# Create our data\n",
    "data = [\n",
    "    [5.0, 3.5, 1.5, 0.2],\n",
    "    [6.5, 3.0, 5.0, 2.0],\n",
    "]\n",
    "\n",
    "# Run our predictions\n",
    "predictions = svc.predict(data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 3\n",
    "\n",
    "1) Import:\n",
    "* StandardScaler from sklearn.preprocessing\n",
    "\n",
    "2) Load the data/housing.csv dataset.\n",
    "\n",
    "3) Create the scaler.\n",
    "\n",
    "4) fit() the entire dataset.\n",
    "\n",
    "5) transform() the entire dataset and save the results to 'scaled_data'.\n",
    "\n",
    "6) Bonus points: can you inverse_transform() the scaled_data?\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Inverse transform is also attached to the scaler instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/housing.csv')\n",
    "\n",
    "# Instantiate scaler.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit scaler\n",
    "ss.fit(df)\n",
    "\n",
    "# Transform data.\n",
    "scaled_data = ss.transform(df)\n",
    "\n",
    "# Bonus: inverse transform data.\n",
    "unscaled_data = ss.inverse_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 4\n",
    "\n",
    "1) Import:\n",
    "* train_test_split from sklearn.model_selection\n",
    "\n",
    "2) Load your data from data/housing.csv. Split:\n",
    "* y: 'Value'\n",
    "* X: everything else\n",
    "\n",
    "3) Use train_test_split with test_size=.30\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Use DataFrame.drop('column', axis=1) to drop a column and return df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data/housing.csv')\n",
    "y = df['Value']\n",
    "X = df.drop('Value', axis=1)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 5\n",
    "\n",
    "1) Import:\n",
    "* GradientBoostingRegressor from sklearn.ensemble;\n",
    "* Pipeline from sklearn.pipeline; and,\n",
    "* Imputer from sklearn.preprocessing.\n",
    "\n",
    "2) Create a pipeline composed of:\n",
    "* An imputer with a missing_values=np.NaN argument;\n",
    "* A standard scaler; and,\n",
    "* A gradient boosting regressor.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Don't forget to name your pipeline steps.\n",
    "\n",
    "**Hint**: Pipelines are composed of a list of tuples:\n",
    "    \n",
    "    Pipeline([\n",
    "        ('step_1', Item()),\n",
    "        ('step_2', Item())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run imports\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create pipeline.\n",
    "pipe = Pipeline([\n",
    "    ('imputer'  , Imputer(missing_values=np.NaN)),\n",
    "    ('scaler'   , StandardScaler()),\n",
    "    ('regressor', GradientBoostingRegressor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 6\n",
    "\n",
    "1) Import:\n",
    "* import mean_squared_error from sklearn.metrics\n",
    "\n",
    "2) Take 'pipe' from Exercise 5 and fit():\n",
    "* 'X_train' from Exercise 4\n",
    "* 'y_train' from Exercise 4.\n",
    "\n",
    "3) predict() using 'X_test' from Exercise 4, and assign to 'y_predicted'\n",
    "\n",
    "4) Get your mean_squared_error from 'y_test' from Excercise 4 and 'y_predicted'.\n",
    "\n",
    "5) Bonus: reconsitute X_test with y_test, y_predicted, and the diff between them.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: nothing new aside from the bonus. Just make sure everything goes in the right spot.\n",
    "\n",
    "**Bonus Hint**: bonus is easiest by creating a y_out dataframe, then concatenating to X_test.\n",
    "\n",
    "**Bonus Hint**: remember to concatenate along the 1 axis (colums) as opposed to the 0 axis (rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean absolute error was:  0.373067437421\n",
      "Which translates to $37,306.74.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ActualValue</th>\n",
       "      <th>PredictedValue</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>2.6639</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.911250</td>\n",
       "      <td>1.041250</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2.441250</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-118.46</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.653157</td>\n",
       "      <td>-0.320157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>2.0754</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.077778</td>\n",
       "      <td>1.092063</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>4.128571</td>\n",
       "      <td>33.97</td>\n",
       "      <td>-118.27</td>\n",
       "      <td>1.014</td>\n",
       "      <td>1.233803</td>\n",
       "      <td>-0.219803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>8.7980</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.187075</td>\n",
       "      <td>1.093537</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>3.074830</td>\n",
       "      <td>33.63</td>\n",
       "      <td>-117.64</td>\n",
       "      <td>4.366</td>\n",
       "      <td>4.081852</td>\n",
       "      <td>0.284148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>5.1619</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.202667</td>\n",
       "      <td>1.053333</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>2.773333</td>\n",
       "      <td>34.25</td>\n",
       "      <td>-118.48</td>\n",
       "      <td>1.953</td>\n",
       "      <td>2.809664</td>\n",
       "      <td>-0.856664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>1.8417</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.770642</td>\n",
       "      <td>1.055046</td>\n",
       "      <td>249.0</td>\n",
       "      <td>2.284404</td>\n",
       "      <td>38.92</td>\n",
       "      <td>-122.62</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.990551</td>\n",
       "      <td>-0.143551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "8916   2.6639      29.0  2.911250   1.041250      1953.0  2.441250     34.02   \n",
       "5139   2.0754      39.0  4.077778   1.092063      2601.0  4.128571     33.97   \n",
       "10377  8.7980      10.0  8.187075   1.093537      1808.0  3.074830     33.63   \n",
       "3516   5.1619      36.0  5.202667   1.053333      1040.0  2.773333     34.25   \n",
       "3333   1.8417      13.0  4.770642   1.055046       249.0  2.284404     38.92   \n",
       "\n",
       "       Longitude  ActualValue  PredictedValue  Difference  \n",
       "8916     -118.46        2.333        2.653157   -0.320157  \n",
       "5139     -118.27        1.014        1.233803   -0.219803  \n",
       "10377    -117.64        4.366        4.081852    0.284148  \n",
       "3516     -118.48        1.953        2.809664   -0.856664  \n",
       "3333     -122.62        0.847        0.990551   -0.143551  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Fit pipe.\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict with pipe.\n",
    "y_predicted = pipe.predict(X_test)\n",
    "\n",
    "# Get your error and print it.\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('Our mean absolute error was: ', mae)\n",
    "print('Which translates to ${:,.2f}.'.format(mae * 100000))\n",
    "\n",
    "# Bonus: Create reconstituted dataframe.\n",
    "y_out = pd.DataFrame({\n",
    "    'ActualValue'   : y_test,\n",
    "    'PredictedValue': y_predicted,\n",
    "    'Difference'    : y_test - y_predicted\n",
    "}, columns=['ActualValue', 'PredictedValue', 'Difference'])\n",
    "\n",
    "# Bonus: Concatenate y_out and X_test\n",
    "pd.concat([X_test, y_out], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 7\n",
    "\n",
    "1) Import:\n",
    "* import cross_val_score from the sklearn.model_selection module.\n",
    "\n",
    "2) Take 'pipe' from Exercise 5 and run a 5-fold cross-validation score with:\n",
    "* X from Exercise 4;\n",
    "* y from Exervise 4; and,\n",
    "* an error type string from the 'scoring' column this [table](http://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
    "\n",
    "3) Print the average error score.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: you are doing a cross-validation so no train/test split is required (i.e. don't use X_train, use X).\n",
    "\n",
    "**Hint**: you are fitting a regressor, so your error scoring will need to be under \"Regression\" in the table. Classifier items will error out.\n",
    "\n",
    "**Hint**: You can find what parameters need to feed model_selection on the API [cross_val_score page](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). It's in the grey box.\n",
    "\n",
    "**Hint**: the 'cv' keyword argument corresponds with the number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our average score is:  -0.41243683707\n"
     ]
    }
   ],
   "source": [
    "# Import cross validation score ()\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Get cross validation score\n",
    "scores = cross_val_score(pipe, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Get mean score\n",
    "avg_score = scores.mean()\n",
    "print('Our average score is: ', avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 8\n",
    "\n",
    "1) Import:\n",
    "* import GridSearchCV from the sklearn.model_selection module.\n",
    "\n",
    "2) Create a parameter grid for your pipeline with so that we test:\n",
    "* 'ls' and 'huber' as your loss function for your regressor; and,\n",
    "* 'n_estimators' is set for 25 instead of 100 to save time.\n",
    "\n",
    "3) Create a grid search for your pipe using your parameter grid. Assign the result to 'best_model'.\n",
    "\n",
    "4) Fit your model on:\n",
    "* X_train from Exercise 4; and,\n",
    "* y_train from Exercise 4.\n",
    "\n",
    "5) Predict X_test with your model.\n",
    "\n",
    "6) Bonus: print out the models best parameters.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Parameter grid template [here](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py). You can also look at the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). It will look something like this (note the double underscore between the name and keyword argument:\n",
    "\n",
    "    grid = {\n",
    "        'regressor__loss'        : ['ls', 'huber'],\n",
    "        'regressor__n_estimators': [25]\n",
    "    }\n",
    "\n",
    "**Hint**: GridSearchCV() will return your optimal model.\n",
    "\n",
    "**Bonus Hint**: the best parameters will be under the .best_params_ attribute of the return value of GridSearchCV()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'regressor__loss': 'ls', 'regressor__n_estimators': 25}\n"
     ]
    }
   ],
   "source": [
    "# Import gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid we want to search.\n",
    "grid = {\n",
    "    'regressor__loss'        : ['ls', 'huber'],\n",
    "    'regressor__n_estimators': [25]\n",
    "}\n",
    "\n",
    "# Define the parameters for our search.\n",
    "best_model = GridSearchCV(\n",
    "    pipe, \n",
    "    n_jobs=2, \n",
    "    param_grid=grid, \n",
    ")\n",
    "\n",
    "# Fit the model ... we are chopping down the data for the sake of time.\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict X_test\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# The model will now have the optimal parameters.\n",
    "print('The best parameters are: {}'.format(best_model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 9\n",
    "\n",
    "1) Pick a dataset to work on from the data folder.\n",
    "\n",
    "2) Load the data and look at it. Pick out feature variables and a target variable.\n",
    "\n",
    "3) If your target is a category, pick a classifier algo. Otherwise pick a regressor algo.\n",
    "\n",
    "4) Scale your data, fit your model, and make some predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: When in doubt, Google!\n",
    "\n",
    "**Hint**: When in doubt, look at the sklearn documentation and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import antigravity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution 10\n",
    "\n",
    "1) Take your algorithm from Exercise 9, and recreate it with tweaked parameters and make predictions on the data.\n",
    "\n",
    "2) Use a scorer of your choice to compare the results of models to see which is better.\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: When in doubt, Google!\n",
    "\n",
    "**Hint**: When in doubt, look at the sklearn documentation and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import antigravity"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
